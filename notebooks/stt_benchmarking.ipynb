{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# bhAI STT Model Benchmarking\n\nBenchmarks multiple Speech-to-Text models against human-reviewed ground truth.\n\n**Workflow:**\n1. Install deps & clone repo\n2. Upload audio zip (one file, ~30 seconds)\n3. Run all models on GPU\n4. Compare WER/CER across models\n5. Download results"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repo\nimport os\n\nREPO_URL = \"https://github.com/sundar911/bhAI_voicebot.git\"\nBRANCH = \"main\"\n\nif not os.path.exists(\"bhAI_voicebot\"):\n    !git clone --branch {BRANCH} {REPO_URL}\n\n%cd bhAI_voicebot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -e \".[benchmarking]\" -q\n!pip install onnxruntime-gpu huggingface_hub -q\n\n# HuggingFace token — paste yours below\nHF_TOKEN = \"\"  # <-- PASTE YOUR HUGGINGFACE TOKEN HERE\n\n!huggingface-cli login --token {HF_TOKEN}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Upload Audio Files\n\nRun the cell below — it will open a file picker. Select `sharepoint_audio.zip` from your machine.\n\nThis zip contains only the 86 question audio files that have ground truth transcriptions (no answer files)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\nfrom google.colab import files\n\n# Upload the audio zip\nprint(\"Select sharepoint_audio.zip from your machine...\")\nuploaded = files.upload()\n\n# Unzip into data/sharepoint_sync/\nzip_name = list(uploaded.keys())[0]\n!mkdir -p data/sharepoint_sync\n!unzip -o {zip_name} -d data/sharepoint_sync/\n\n# Show what we got\nfor domain in [\"helpdesk\", \"hr_admin\", \"production\"]:\n    d = Path(f\"data/sharepoint_sync/{domain}\")\n    count = len(list(d.glob(\"*\"))) if d.exists() else 0\n    print(f\"  {domain}: {count} files\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Go to Runtime > Change runtime type > T4 GPU\")\n",
    "\n",
    "# Count downloaded audio files\n",
    "from pathlib import Path\n",
    "for domain in [\"helpdesk\", \"hr_admin\", \"production\"]:\n",
    "    d = Path(f\"data/sharepoint_sync/{domain}\")\n",
    "    count = len(list(d.glob(\"*\"))) if d.exists() else 0\n",
    "    print(f\"  {domain}: {count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify ground truth xlsx\n",
    "import sys\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from benchmarking.scripts.load_ground_truth import load_ground_truth\n",
    "\n",
    "gt = load_ground_truth()\n",
    "print(f\"Ground truth entries: {len(gt)}\")\n",
    "\n",
    "# Show breakdown by domain\n",
    "from collections import Counter\n",
    "domains = Counter(k.split(\"/\")[0] for k in gt)\n",
    "for d, c in domains.most_common():\n",
    "    print(f\"  {d}: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Test — Verify One Model Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bhai.stt.registry import get_stt, list_models\n",
    "\n",
    "print(\"Available models:\", list_models())\n",
    "\n",
    "# Quick test with meta_mms (smallest model, ~2GB)\n",
    "stt = get_stt(\"meta_mms\", work_dir=Path(\".bhai_temp/test\"), device=\"cuda\")\n",
    "\n",
    "# Find a test audio file\n",
    "test_files = list(Path(\"data/sharepoint_sync\").glob(\"**/*.ogg\"))[:1]\n",
    "if test_files:\n",
    "    result = stt.transcribe(test_files[0])\n",
    "    print(f\"\\nFile: {test_files[0].name}\")\n",
    "    print(f\"Transcription: {result['text']}\")\n",
    "    stt.cleanup()\n",
    "    print(\"\\nQuick test passed!\")\n",
    "else:\n",
    "    print(\"No audio files found — check step 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run All Models\n",
    "\n",
    "This runs each model sequentially across all audio files for each domain.\n",
    "Models are loaded one at a time to manage GPU memory.\n",
    "\n",
    "**Estimated time**: ~30-60 min per domain depending on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Select which models and domains to benchmark\nMODELS = [\n    \"vaani_whisper\",\n    \"indic_conformer\",\n    \"whisper_large_v3\",\n    \"meta_mms\",\n    \"indic_wav2vec\",\n]\n\nDOMAINS = [\"hr_admin\", \"helpdesk\", \"production\"]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks\n",
    "for domain in DOMAINS:\n",
    "    input_dir = f\"data/sharepoint_sync/{domain}\"\n",
    "    if not Path(input_dir).exists():\n",
    "        print(f\"Skipping {domain} — no audio directory\")\n",
    "        continue\n",
    "\n",
    "    for model in MODELS:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"# {model} on {domain}\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        !python benchmarking/scripts/generate_initial_transcriptions.py \\\n",
    "            --model {model} \\\n",
    "            --input {input_dir} \\\n",
    "            --domain {domain} \\\n",
    "            --device cuda \\\n",
    "            --append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison for each domain\n",
    "for domain in DOMAINS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {domain.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    !python benchmarking/scripts/compare_models.py \\\n",
    "        --domain {domain} \\\n",
    "        --output benchmarking/results/comparison_{domain}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results as a pandas table (if pandas available)\n",
    "try:\n",
    "    import pandas as pd\n",
    "\n",
    "    for domain in DOMAINS:\n",
    "        csv_path = f\"benchmarking/results/comparison_{domain}.csv\"\n",
    "        if Path(csv_path).exists():\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"\\n{domain.upper()}:\")\n",
    "            display(df.sort_values(\"wer\"))\n",
    "except ImportError:\n",
    "    print(\"Install pandas for table display: pip install pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download comparison CSVs and per-model JSONL files\n",
    "from google.colab import files\n",
    "\n",
    "for domain in DOMAINS:\n",
    "    csv_path = f\"benchmarking/results/comparison_{domain}.csv\"\n",
    "    if Path(csv_path).exists():\n",
    "        files.download(csv_path)\n",
    "\n",
    "# Also download all transcription JSONL files\n",
    "import shutil\n",
    "shutil.make_archive(\"transcription_results\", \"zip\", \"data/transcription_dataset\")\n",
    "files.download(\"transcription_results.zip\")\n",
    "\n",
    "print(\"Done! Results downloaded.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}